# ------------------------------
# README.md

# 📚 Get me a book with AI

An intelligent book management system built with FastAPI and PostgreSQL, integrated with a LLaMA3-based local AI model for generating book and review summaries. Includes user reviews, recommendations, authentication, CI/CD, Docker, and more.

---

## 🚀 Features

- Add, update, delete, and fetch books
- Manage user reviews and ratings
- Generate book and review summaries using AI (LLaMA3 or placeholder)
- Get book recommendations
- Secure API endpoints with basic token auth
- Fully asynchronous operations
- Containerized with Docker & Docker Compose
- CI/CD pipeline using GitHub Actions
- Unit and integration tested using `pytest`
- 🌐 OpenAPI-compliant RESTful API with Swagger and Redoc support

---

## 🏗️ Project Structure

```
book-ai-system/
│
├── app/
│   ├── main.py                  # FastAPI entrypoint
│   ├── api/                     # API endpoints
│   ├── models/                  # ORM Models
│   ├── schemas/                 # Pydantic Schemas
│   ├── services/                # Business logic (AI, recommendation)
│   ├── db/                      # DB session and CRUD logic
│   ├── utils/                   # Auth and logging
│   └── tests/                   # Unit & integration tests
│       ├── test_books.py
│       ├── test_reviews.py
│       ├── test_summary.py
│       └── test_integration.py  # Full integration test cases
│
├── Dockerfile
├── docker-compose.yml
├── requirements.txt
├── .github/workflows/ci-cd.yml # GitHub Actions
└── README.md
```

---

## 🐳 Docker Setup

```bash
# Build and run with Docker Compose
docker-compose up --build
```

API runs at: [http://localhost:8000](http://localhost:8000)

To deploy on a cloud server (e.g. AWS EC2):
```bash
# SSH into your EC2 instance
ssh -i <key.pem> ubuntu@<EC2-IP>

# Install Docker
sudo apt update && sudo apt install docker.io docker-compose -y

# Clone and run
git clone https://github.com/your-username/book-ai-system.git
cd book-ai-system
docker-compose up --build -d
```

---

## 🔐 Authentication

This project uses a dummy bearer token:
```bash
Authorization: Bearer dummy_token
```
Update `auth.py` to integrate a real token-based authentication (e.g., JWT).

---

## 📊 Testing

```bash
pytest
```

Includes:

- ✅ Unit tests for individual components
- 🔁 Integration tests for full request/response lifecycle

### Integration Testing
Integration tests live in `test_integration.py`. These tests spin up a test client against the running API and verify end-to-end functionality like:

- Adding and retrieving books
- Submitting and fetching reviews
- Triggering AI-based summaries

You can run integration tests using:
```bash
pytest app/tests/test_integration.py
```

---

## 🧠 AI Summarizer

A simple interface to LLaMA3 or placeholder summary generator. Replace dummy logic in `SummarizerService` with actual model call via HuggingFace, Ollama, Groq, or LangChain.

---

## 🛠️ API Documentation

### Swagger (OpenAPI Spec)

The OpenAPI spec is auto-generated by FastAPI and can be accessed at:

- Swagger UI: [http://localhost:8000/docs](http://localhost:8000/docs)
- Redoc: [http://localhost:8000/redoc](http://localhost:8000/redoc)

These tools provide interactive exploration and testing of the API.

To export the OpenAPI schema manually:

```bash
curl http://localhost:8000/openapi.json -o openapi-schema.json
```

You can then use this file to:

- Import into Postman
- Generate SDKs using [OpenAPI Generator](https://openapi-generator.tech/)
- Document your API using tools like Stoplight or SwaggerHub

---

## 🧬 CI/CD Workflow

- Trigger: On push or PR to `main`
- Steps:
  - Checkout repo
  - Set up Python 3.11
  - Install dependencies
  - Run tests
  - Build Docker image
  - Launch Docker Compose
  - Cleanup

Location: `.github/workflows/ci-cd.yml`

---

## 📦 Environment Variables

Defined in `docker-compose.yml`:

```
DATABASE_URL=postgresql+asyncpg://user:password@db:5432/books_db
```

---

## ☁️ Cloud Deployment (Optional)

1. Provision an EC2 instance on AWS
2. Set up RDS for PostgreSQL (replace DB URL in Docker Compose)
3. Use AWS S3 for storing model files if needed
4. Optional: deploy AI model via SageMaker

---

## 📚 Future Enhancements

- OAuth2 or JWT auth
- AWS deployment (EC2, RDS, S3)
- Redis caching for recommendations
- Integration with LangChain/LlamaIndex
- Model management with AWS SageMaker

---

## 📝 License

MIT License

---

## 👨‍💻 Author

Made with ❤️ by Vikas Singh Chouhan
